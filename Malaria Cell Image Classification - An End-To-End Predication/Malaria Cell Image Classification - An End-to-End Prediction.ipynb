{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Malaria Cell Image Classification – An End-to-End Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This article will discuss building a system that can detect malaria from cell images. The plan will be created in the form of a web application that can make it easier for users and even make it easier for developers who make webs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Algorithm for Classification Malaria Cell Image Using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do after getting the dataset is to perform an image data generator, which rescales the image and then sets the target size (150, 150) and then divides the data into training and test data. For the classification of malaria cell images, preprocessing does not take a long time. After preprocessing, we create a deep learning architecture using a Convolutional Neural Network. In this section, we have to define the number of convolutions that we will operate along with the activation function, kernel size, filters, and the number of dense layers of how many neurons to set. Then to compile the model, we need loss, optimizer, and metrics. Next, to fit the model, we must set the number of epochs, validation step, step per epoch, and verbose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset source : https://www.kaggle.com/iarunava/cell-images-for-detecting-malaria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import the librairies\n",
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image data generator \n",
    "datagen=ImageDataGenerator(\n",
    "                            rescale=1.0/255,\n",
    "                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir=\"C:\\\\Users\\\\Owner\\\\Desktop\\\\Malaria Detection Model\\\\malaria_dataset\\\\cell_images\\\\cell_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22048 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_directory(directory=path_dir,\n",
    "                                            target_size=(150,150),\n",
    "                                            shuffle=True,\n",
    "                                            subset='training'\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5510 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator=datagen.flow_from_directory(directory=path_dir,\n",
    "                                            target_size=(150,150),\n",
    "                                            shuffle=True,\n",
    "                                            subset='validation'\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a model which takes (None, 150, 150, 3) input. Stack 4 convolutional layers with kernel size (3, 3) with a growing number of filters (32, 64, 128, 128). Add 2×2 pooling layer after every 2 convolutional layers (conv-conv-pool scheme). Add a dense layer with 512 neurons and a second dense layer with two neurons for classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function : relu and sigmoid \n",
    "model=tf.keras.models.Sequential([\n",
    "    # first_convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    # Second_convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    # third_convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,4), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    # fourth_convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compile model, with adam optimizer and  binary cross-entropy for loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit Model , with 25 steps_per_epoch, 20 epochs, 5 validation_steps, and 2 verbose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 25 steps, validate for 5 steps\n",
      "Epoch 1/20\n",
      "25/25 - 56s - loss: 0.7008 - accuracy: 0.5031 - val_loss: 0.6895 - val_accuracy: 0.5312\n",
      "Epoch 2/20\n",
      "25/25 - 54s - loss: 0.6762 - accuracy: 0.5987 - val_loss: 0.6959 - val_accuracy: 0.4719\n",
      "Epoch 3/20\n",
      "25/25 - 61s - loss: 0.6890 - accuracy: 0.5444 - val_loss: 0.6503 - val_accuracy: 0.6500\n",
      "Epoch 4/20\n",
      "25/25 - 60s - loss: 0.6128 - accuracy: 0.6844 - val_loss: 0.4620 - val_accuracy: 0.7906\n",
      "Epoch 5/20\n",
      "25/25 - 61s - loss: 0.4419 - accuracy: 0.8056 - val_loss: 0.2889 - val_accuracy: 0.9031\n",
      "Epoch 6/20\n",
      "25/25 - 59s - loss: 0.2855 - accuracy: 0.8869 - val_loss: 0.2578 - val_accuracy: 0.8906\n",
      "Epoch 7/20\n",
      "25/25 - 61s - loss: 0.1996 - accuracy: 0.9244 - val_loss: 0.2243 - val_accuracy: 0.9156\n",
      "Epoch 8/20\n",
      "25/25 - 60s - loss: 0.2105 - accuracy: 0.9431 - val_loss: 0.1948 - val_accuracy: 0.9187\n",
      "Epoch 9/20\n",
      "25/25 - 63s - loss: 0.1602 - accuracy: 0.9469 - val_loss: 0.2320 - val_accuracy: 0.9281\n",
      "Epoch 10/20\n",
      "25/25 - 61s - loss: 0.1878 - accuracy: 0.9362 - val_loss: 0.1547 - val_accuracy: 0.9187\n",
      "Epoch 11/20\n",
      "25/25 - 61s - loss: 0.1503 - accuracy: 0.9575 - val_loss: 0.2190 - val_accuracy: 0.9375\n",
      "Epoch 12/20\n",
      "25/25 - 61s - loss: 0.1393 - accuracy: 0.9500 - val_loss: 0.1462 - val_accuracy: 0.9625\n",
      "Epoch 13/20\n",
      "25/25 - 61s - loss: 0.1659 - accuracy: 0.9650 - val_loss: 0.1912 - val_accuracy: 0.9187\n",
      "Epoch 14/20\n",
      "25/25 - 63s - loss: 0.1598 - accuracy: 0.9488 - val_loss: 0.1978 - val_accuracy: 0.9125\n",
      "Epoch 15/20\n",
      "25/25 - 60s - loss: 0.1494 - accuracy: 0.9519 - val_loss: 0.2261 - val_accuracy: 0.9375\n",
      "Epoch 16/20\n",
      "25/25 - 61s - loss: 0.1926 - accuracy: 0.9488 - val_loss: 0.1811 - val_accuracy: 0.9438\n",
      "Epoch 17/20\n",
      "25/25 - 64s - loss: 0.2271 - accuracy: 0.9262 - val_loss: 0.1616 - val_accuracy: 0.9438\n",
      "Epoch 18/20\n",
      "25/25 - 61s - loss: 0.1513 - accuracy: 0.9588 - val_loss: 0.1563 - val_accuracy: 0.9625\n",
      "Epoch 19/20\n",
      "25/25 - 61s - loss: 0.1481 - accuracy: 0.9550 - val_loss: 0.1322 - val_accuracy: 0.9500\n",
      "Epoch 20/20\n",
      "25/25 - 61s - loss: 0.1326 - accuracy: 0.9631 - val_loss: 0.1602 - val_accuracy: 0.9438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d2fc8f50f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit\n",
    "model.fit(\n",
    "          train_generator,\n",
    "          steps_per_epoch=25,\n",
    "          epochs=20,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=5,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on the fit model results, we can see the accuracy of the training and validate its accuracy. The training accuracy is 0.9525 or 95.25%, and the validation accuracy is 91.25%.\n",
    "- Save Model and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAve model \n",
    "model.save('malaria_cell.h5') # the model is saved with name malaria_cell.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix to sse the test results\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[2808    0]\n",
      " [   0 2702]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred=model.predict(validation_generator)\n",
    "y_pred=np.argmax(pred, axis=1)\n",
    "y_true=np.argmax(pred, axis=1)\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "# confusion matrix\n",
    "f, ax=plt.subplots(figsize=(8,4))\n",
    "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt='.0f', ax=ax)\n",
    "plt.xlabel('y_pred')\n",
    "plt.ylabel('y_true')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 0 label is Parasitized and 1 label is Uninfected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
